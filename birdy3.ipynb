{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# This is a test - To improve upon model accuracy.  @author Shaela , August 2022\n",
    "#\n",
    "#  Same dataset for bird identification using bird songs.\n",
    "#\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sweet are the beginnings !! \n",
      "********** !**********\n"
     ]
    }
   ],
   "source": [
    "import os, sys, numpy,scipy\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import tensorflow_estimator, tensorboard\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "\n",
    "import tensorflow.keras.utils\n",
    "import tensorflow.keras.activations\n",
    "import tensorflow.keras.applications\n",
    "import tensorflow.keras.callbacks\n",
    "import tensorflow.keras.initializers\n",
    "from tensorflow.keras import losses,metrics\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Audio file processing\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "# EXTRA EXTRA - because they don't work upstairs?\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Start Code Here.\n",
    "print(\"  Sweet are the beginnings !! \")\n",
    "print(\"********** !**********\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 5, 5, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 256)               13107456  \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 20)                5140      \n",
      "=================================================================\n",
      "Total params: 36,766,100\n",
      "Trainable params: 16,593,940\n",
      "Non-trainable params: 20,172,160\n",
      "_________________________________________________________________\n",
      "------Model Summary----------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# The Convolutional Base of the Pre-Trained Model will be added as a Layer in this Model\n",
    "Conv_Base = tf.keras.applications.resnet50.ResNet50(include_top = False, weights = 'imagenet', input_shape = (150,150, 3))\n",
    "\n",
    "for layer in Conv_Base.layers[:-8]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv_Base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 256, activation = 'relu'))\n",
    "model.add(Dense(units = 256, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(20, activation = 'softmax'))\n",
    "\n",
    "model.summary()\n",
    "print(\"------Model Summary----------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create DATA generators for the model.\n",
      "\n",
      "Found 484 images belonging to 20 classes.\n",
      "Found 112 images belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#base_dir = 'Deep_Learning_With_Python_Book/Dogs_Vs_Cats_Small'\n",
    "#if os.path.exists(base_dir):\n",
    "#    train_dir = os.path.join(base_dir, 'train')\n",
    "#    validation_dir = os.path.join(base_dir, 'validation')\n",
    "#    test_dir = os.path.join(base_dir, 'test')\n",
    "#else:\n",
    "#    print(\"The Folder, {}, doesn't exist'\".format(base_dir))\n",
    "\n",
    "\n",
    "print(\"Create DATA generators for the model.\\n\")\n",
    "\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255,validation_split=0.2,dtype = 'float32', preprocessing_function=tf.keras.applications.resnet.preprocess_input) # Training and Validation split 80/20\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "#Train_Datagen = ImageDataGenerator(dtype = 'float32', preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
    "#Val_Datagen = ImageDataGenerator(dtype = 'float32', preprocessing_function=tf.keras.applications.resnet.preprocess_input)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(directory = './img_data2',\n",
    "                                        target_size = (150,150),\n",
    "                                        batch_size = batch_size,\n",
    "                                        class_mode = 'categorical',subset=\"training\",\n",
    "                                        seed=42)\n",
    "\n",
    "val_gen = datagen.flow_from_directory(directory = './img_data2',\n",
    "                                      target_size = (150,150),\n",
    "                                      batch_size = batch_size, class_mode = 'categorical',\n",
    "                                      subset=\"validation\",seed=42)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Model\n",
    "rcallback = [ModelCheckpoint(filepath='./models/bestTryModel.hdf5', monitor='val_loss', save_best_only=True, mode='auto')]\n",
    "\n",
    "epochs = 1000\n",
    "Number_Of_Training_Images = train_gen.classes.shape[0]\n",
    "steps_per_epoch = Number_Of_Training_Images/batch_size\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=3e-4),\n",
    "              loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(train_gen, epochs = epochs,\n",
    "                    #batch_size = batch_size,\n",
    "                    validation_data = val_gen, callbacks=rcallback,\n",
    "                    steps_per_epoch = steps_per_epoch)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "No_Of_Epochs = range(epochs)\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(No_Of_Epochs, train_acc, marker = 'o', color = 'blue', markersize = 12,\n",
    "                 linewidth = 2, label = 'Training Accuracy')\n",
    "plt.plot(No_Of_Epochs, val_acc, marker = '.', color = 'red', markersize = 12,\n",
    "                 linewidth = 2, label = 'Validation Accuracy')\n",
    "\n",
    "plt.title('Training Accuracy and Testing Accuracy w.r.t Number of Epochs')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(No_Of_Epochs, train_loss, marker = 'o', color = 'blue', markersize = 12,\n",
    "                 linewidth = 2, label = 'Training Loss')\n",
    "plt.plot(No_Of_Epochs, val_acc, marker = '.', color = 'red', markersize = 12,\n",
    "                 linewidth = 2, label = 'Validation Loss')\n",
    "\n",
    "plt.title('Training Loss and Testing Loss w.r.t Number of Epochs')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}