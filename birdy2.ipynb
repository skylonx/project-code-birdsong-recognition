{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#******************************************************************************************************************************************************#\n",
    "\"\"\"\n",
    "    @author Shaela Khan, Created : 12th August, Last Updated 26th August, Friday 2022.\n",
    "\n",
    "#  birdy2.ipynb  -> Experimentation\n",
    "#  Bird Recognition from birdsongs using Deep learning ->s\n",
    "#  DataSource : - https://www.kaggle.com/datasets/rtatman/british-birdsong-dataset  (Aggregated from the original Xeno-Canto Dataset.)\n",
    "#  Provided dataset has a directory with - ./dataset/ --> Original audio dataset.\n",
    "#                                        -   ./img_data2 --> audio files converted into image files --> contains spectrographs of audio data.\n",
    "#\n",
    "#\n",
    "#  We then create a CNN model with possible usage of pre-trained models, that can identify the difference classes defined - this is a supervised learning\n",
    "#  problem.\n",
    "#  Input: birdsong_metadata.csv + songs\n",
    "#  Output : T\n",
    "\"\"\"\n",
    "#*******************************************************************************************************************************************************#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World ! \n",
      "********** !**********\n",
      "\n",
      " Tensorflow version:  2.2.0\n",
      "Hello Experiment.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from librosa import core, onset, feature, display\n",
    "import soundfile as sf\n",
    "import umap\n",
    "from IPython.display import Audio\n",
    "import sklearn\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os,sys,random,math\n",
    "from random import seed, random, randint\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "# import import_ipynb,import nbimporter , import helper-functions\n",
    "\n",
    "\n",
    "# FILE PROCESSING\n",
    "import csv\n",
    "import pandas as pd\n",
    "import shutil\n",
    "from shutil import move\n",
    "from itertools import groupby\n",
    "\n",
    "# Plotting AND Visuals.\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, shutil, itertools, pickle,seaborn as sn, math, time,scipy\n",
    "\n",
    "# Stats\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import spatial\n",
    "\n",
    "\n",
    "# Image processing libraries\n",
    "#!pip install Pillow\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# EXTRA -\n",
    "%matplotlib inline\n",
    "\n",
    "# ML, statistics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "# TENSORFLOW LIBRARIES. BACK-END SUPPORT.\n",
    "# Creating Model and model Evaluation\n",
    "import tensorflow as tf\n",
    "import tensorboard,tensorflow_estimator\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, GlobalAveragePooling1D, AveragePooling2D, Input, Add\n",
    "from tensorflow.keras.optimizers import Adam,SGD,RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "\n",
    "import tensorflow.keras.utils\n",
    "import tensorflow.keras.activations\n",
    "import tensorflow.keras.applications\n",
    "import tensorflow.keras.callbacks\n",
    "import tensorflow.keras.initializers\n",
    "from tensorflow.keras import losses,metrics\n",
    "\n",
    "\n",
    "# Audio file processing\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "\n",
    "\n",
    "# EXTRA EXTRA - because they don't work upstairs?\n",
    "import pydub\n",
    "from pydub import AudioSegment\n",
    "import IPython\n",
    "from IPython.display import Audio\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Start Code Here.\n",
    "print(\"Hello World ! \")\n",
    "print(\"********** !**********\")\n",
    "print(\"\\n Tensorflow version: \", tf.__version__)\n",
    "\n",
    "\n",
    "print(\"Hello Experiment.\")\n",
    "\n",
    "# Helper function- to be moved to helper-functions.ipynb\n",
    "from datetime import datetime\n",
    "def timer():\n",
    "    # datetime object containing current date and time\n",
    "    now = datetime.now()\n",
    "    print(\"now =\", now)\n",
    "    # dd/mm/YY H:M:S\n",
    "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    print(\"date and time =\", dt_string)\n",
    "\n",
    "print(\"\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "genres = \"northern cardinal,northern flicker,northern mockingbird,northern parula,northern pintail,northern roughwinged swallow,northern shoveler,northern waterthrush,nuttells woodpecker,olive sided flycatcher,orange crowned warbler,peregrine falcon,phainopepla,pied billed grebe,rose breasted grosbeak,snowgoose,sora,stellers jay,wild turkey, yellow billed flycatcher\".split(',')\n",
    "#print(genres)\n",
    "\n",
    "\n",
    "# CONVERTING BIRD SONGS WHICH ARE AUDIO FILES INTO IMAGE FILES- FOR TEST DATA --> iMAGES ARE SPECTROGRAPHS OF THE AUDIO DATA.\n",
    "\n",
    "cmap = plt.get_cmap('inferno')\n",
    "plt.figure(figsize=(8,8))\n",
    "#pathlib.Path('img_data2/').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for g in genres:\n",
    "    pathlib.Path('img_data2/'+g).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir('./dataset/'+g+'/'):\n",
    "        songname = './dataset/'+g+'/'+filename\n",
    "        y, sr = librosa.load(songname, mono=True, duration=5)\n",
    "        print(y.shape)\n",
    "        plt.specgram(y, NFFT=2048, Fs=2, Fc=0, noverlap=128, cmap=cmap, sides='default', mode='default', scale='dB');\n",
    "        plt.axis('off')\n",
    "        base = os.path.splitext(filename)[0]\n",
    "        # os.rename(my_file, base + '.bin')\n",
    "        plt.savefig('img_data2/'+g+'/'+base+'.png')\n",
    "        #plt.savefig('img_data2/{g}/{filename[:-3].replace(\".\", \"\")}.png')\n",
    "        plt.clf()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Creating data generators.\n",
    "# rescale all pixel values from 0-255, so after this step all our pixel values are in range (0,1)#train_df['labels'] = train_df['english_cname'].astype(str)\n",
    "\n",
    "print(\"Create DATA generators for the model.\\n\")\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255,validation_split=0.3) # Training and Validation split 70/30\n",
    "#test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "\n",
    "train_set =datagen.flow_from_directory('./img_data2/',\n",
    "                                       target_size=(224,224),batch_size=8,\n",
    "                                       class_mode='categorical',subset=\"training\",\n",
    "                                       seed=42,\n",
    "                                       shuffle = False)\n",
    "print('Train generator created')\n",
    "\n",
    "validation_set = datagen.flow_from_directory('./img_data2/',\n",
    "                                             target_size=(224, 224),\n",
    "                                             batch_size=8,class_mode='categorical',\n",
    "                                             subset=\"validation\",seed=42,\n",
    "                                             shuffle = False )\n",
    "\n",
    "\n",
    "print('Validation generator created')\n",
    "\n",
    "\n",
    "# test_set =test_datagen.flow_from_directory(test_df,target_size=(64, 64),\n",
    "                                          # batch_size=32, class_mode='categorical', shuffle = False)\n",
    "\n",
    "\n",
    "\n",
    "# test_gen=tvgen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels',target_size=img_size,\n",
    "                                  # class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=2)\n",
    "train_image ,train_labels = train_set.next()\n",
    "val_image, val_labels = validation_set.next()\n",
    "\n",
    "\n",
    "print(\"\\n ImageGenerator created data train set    :  \",train_image.shape)\n",
    "print(\"\\n ImageGenerator created data validation set:  \",val_image.shape)\n",
    "print(\"\\n Sanity check Line.----------\")\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Printing labels of the validation dataset: \\n\",val_generator.labels)\n",
    "#print(\"Printing label- names  of the training dataset: \\n\",train_labels)\n",
    "#print(\"Printing label- names  of the validation dataset: \\n\",val_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "resnet50 = keras.applications.resnet50\n",
    "\n",
    "# Model Creation\n",
    "dropout_dense_layer = 0.3\n",
    "conv_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "for layer in conv_model.layers:\n",
    "    layer.trainable = False\n",
    "x = tf.keras.layers.Flatten()(conv_model.output)\n",
    "x = tf.keras.layers.Dense(100, activation='relu')(x)\n",
    "x = tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\n",
    "x = tf.keras.layers.Dense(100, activation='relu')(x)\n",
    "x = tf.keras.layers.Dense(100, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(dropout_dense_layer)(x)\n",
    "predictions = tf.keras.layers.Dense(20, activation='softmax')(x)\n",
    "full_model = tf.keras.models.Model(inputs=conv_model.input, outputs=predictions)\n",
    "full_model.summary()\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step : 2 Training and running the model.  RESNET50 ---> The right way??\n",
    "\n",
    "rcallback = [ModelCheckpoint(filepath='./models/bestModel.hdf5', monitor='val_loss', save_best_only=True, mode='auto')]\n",
    "\n",
    "full_model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=keras.optimizers.Adam(lr=0.005),\n",
    "                  metrics=['acc'])\n",
    "\n",
    "\n",
    "history__ = full_model.fit(train_set,\n",
    "                           validation_data = validation_set,\n",
    "                           callbacks=rcallback,\n",
    "                           epochs=50)\n",
    "timer()\n",
    "full_model.save_weights('resnet50.h5')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Declare variables required for prediction case.\n",
    "classes_to_predict = genres\n",
    "validation_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Create dataframe of the predictions --taking in fraction of the data slice.\n",
    "preds = full_model.predict(validation_set)\n",
    "validation_df = pd.DataFrame(columns=[\"prediction\", \"groundtruth\", \"correct_prediction\"])\n",
    "\n",
    "\n",
    "for pred, groundtruth in zip(preds[:20], validation_set.__getitem__(0)[1]):\n",
    "    validation_df = validation_df.append({\"prediction\":classes_to_predict[np.argmax(pred)],\n",
    "                                       \"groundtruth\":classes_to_predict[np.argmax(groundtruth)],\n",
    "                                       \"correct_prediction\":np.argmax(pred)==np.argmax(groundtruth)}, ignore_index=True)\n",
    "\n",
    "print(\"Predictions: \\n\")\n",
    "print(validation_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Say something.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Say something.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}